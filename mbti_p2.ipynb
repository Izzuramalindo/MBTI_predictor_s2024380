{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "import pickle as pkl\n",
    "from scipy import sparse\n",
    "\n",
    "# Data Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wordcloud\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "# Text Processing\n",
    "import re\n",
    "import itertools\n",
    "import string\n",
    "import collections\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Machine Learning packages\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.manifold import TSNE\n",
    "import joblib\n",
    "\n",
    "# Model training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Models\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, balanced_accuracy_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, multilabel_confusion_matrix, confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Ignore noise warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#extract lyrics\n",
    "import lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eda\n",
    "p2_survey = pd.read_csv('../python/mbtidata.csv')\n",
    "#p2 = pd.read_csv('../python/p2_lyric1000.csv')\n",
    "#remove unwanted words in order to get valid model accuracy estimation for unseen data. \n",
    "remove_words = '|'.join(['Chorus', 'Lyrics', 'Intro', 'Verse','Outro','Post-Chorus:','Pre-Chorus', 'Embed','Bridge'])\n",
    "p2_survey[\"lyrics\"] = p2_survey[\"lyrics\"].str.replace(remove_words, '')\n",
    "p2_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p2_survey ['all_lyrics'] = new_df['lyrics']\n",
    "#p2_survey['MBTI'] = p2['MBTI_Type'].str.split('-').str[0]\n",
    "p2_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p2_survey.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#size of dataset\n",
    "nRow, nCol = p2_survey.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_survey.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2_survey = p2_survey[['MBTI', 'TopSongs','lyrics']]\n",
    "p2_survey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#all values are textual, hence they have to be converted to numerical form to train the ML model\n",
    "p2_survey.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the unique values from the 'MBTI_Type' of personality column\n",
    "types = np.unique(np.array(p2_survey['MBTI']))\n",
    "types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = p2_survey.groupby(['MBTI']).count()*50\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,4))\n",
    "plt.bar(np.array(total.index), height = total['lyrics'],)\n",
    "plt.xlabel('Personality types', size = 14)\n",
    "plt.ylabel('No. of lyrics count available', size = 14)\n",
    "plt.title('Total lyrics count for each personality type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "#Plotting this in descending order for better understanding of this visualization\n",
    "cnt_srs = p2_survey['MBTI'].value_counts()\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.barplot(cnt_srs.index, cnt_srs.values, alpha=0.8)\n",
    "plt.xlabel('Personality types', fontsize=12)\n",
    "plt.ylabel('No. of lyrics availables', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the most common users personality is \n",
    "INFP (Introvert Intuition Feeling Perceiving).\n",
    "\n",
    "#can consider for now that users who's willing to fill up the survey are more intoverted, perceptive, and emotional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p2.tail()\n",
    "p2_survey['lyrics'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p2_survey[p2_survey['lyrics'].isna()] # print row with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p2['lyric']=p2['lyric'].fillna(\"\") # change nan to \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the most common words in all posts.\n",
    "words = list(p2_survey[\"lyrics\"].apply(lambda x: x.split()))\n",
    "words = [x for y in words for x in y]\n",
    "Counter(words).most_common(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the most common words with WordCloud.\n",
    "wc = wordcloud.WordCloud(width=1200, height=500, \n",
    "                         collocations=False, background_color=\"white\", \n",
    "                         colormap=\"tab20b\").generate(\" \".join(words))\n",
    "\n",
    "# collocations to False  is set to ensure that the word cloud doesn't appear as if it contains any duplicate words\n",
    "plt.figure(figsize=(25,10))\n",
    "# generate word cloud, interpolation \n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "_ = plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(p2_survey['MBTI'].unique()), sharex=True, figsize=(15,len(p2_survey['MBTI'].unique())))\n",
    "k = 0\n",
    "for i in p2_survey['MBTI'].unique():\n",
    "    df_4 = p2_survey[p2_survey['MBTI'] == i]\n",
    "    wordcloud = WordCloud(max_words=1628,relative_scaling=1,normalize_plurals=False).generate(df_4['lyrics'].to_string())\n",
    "    plt.subplot(4,4,k+1)\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(i)\n",
    "    ax[k].axis(\"off\")\n",
    "    k+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = p2_survey[['MBTI','lyrics']]\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns for personality type indicators\n",
    "def get_types(row):\n",
    "    t=row['MBTI']\n",
    "\n",
    "    I = 0; N = 0\n",
    "    T = 0; J = 0\n",
    "    \n",
    "    if t[0] == 'I': I = 1\n",
    "    elif t[0] == 'E': I = 0\n",
    "    else: print('I-E not found') \n",
    "        \n",
    "    if t[1] == 'N': N = 1\n",
    "    elif t[1] == 'S': N = 0\n",
    "    else: print('N-S not found')\n",
    "        \n",
    "    if t[2] == 'T': T = 1\n",
    "    elif t[2] == 'F': T = 0\n",
    "    else: print('T-F not found')\n",
    "        \n",
    "    if t[3] == 'J': J = 1\n",
    "    elif t[3] == 'P': J = 0\n",
    "    else: print('J-P not found')\n",
    "    return pd.Series( {'IE':I, 'NS':N , 'TF': T, 'JP': J }) \n",
    "\n",
    "data = data.join(data.apply (lambda row: get_types (row),axis=1))\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using the above code, if a person has I, N, T and J, the value across the 4 axis of MBTI i.e. IE, NS, TF and JP respectively, will be 1. Else 0.\n",
    "\n",
    "This will help us calculate for e.g. how many Introvert posts are present v/s how many Extrovert posts are presnt, out of all the given entries in our labelled Kaggle dataset. This is done in order to extplore the dataset for all the individual Personality Indices of MBTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting No. of posts in one class / Total no. of posts in the other class\n",
    "\n",
    "print (\"Introversion (I) /  Extroversion (E):\\t\", data['IE'].value_counts()[0], \" / \", data['IE'].value_counts()[1])\n",
    "print (\"Intuition (N) / Sensing (S):\\t\\t\", data['NS'].value_counts()[0], \" / \", data['NS'].value_counts()[1])\n",
    "print (\"Thinking (T) / Feeling (F):\\t\\t\", data['TF'].value_counts()[0], \" / \", data['TF'].value_counts()[1])\n",
    "print (\"Judging (J) / Perceiving (P):\\t\\t\", data['JP'].value_counts()[0], \" / \", data['JP'].value_counts()[1])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "there is unequal distribution even among each of the 4 axis in the entries of out dataset. i.e. out of NS:S is the majority, in TF:T is the majority. While IE and JP have realtively less differnce between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the distribution of each personality type indicator\n",
    "N = 4\n",
    "bottom = (data['IE'].value_counts()[0], data['NS'].value_counts()[0], data['TF'].value_counts()[0], data['JP'].value_counts()[0])\n",
    "top = (data['IE'].value_counts()[1], data['NS'].value_counts()[1], data['TF'].value_counts()[1], data['JP'].value_counts()[1])\n",
    "\n",
    "ind = np.arange(N)    # the x locations for the groups\n",
    "# the width of the bars\n",
    "width = 0.7           # or len(x) can also be used here\n",
    "\n",
    "p1 = plt.bar(ind, bottom, width, label=\"I, N, T, F\")\n",
    "p2 = plt.bar(ind, top, width, bottom=bottom, label=\"E, S, F, P\") \n",
    "\n",
    "plt.title('Distribution accoss types indicators')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(ind, ('I / E',  'N / S', 'T / F', 'J / P',))\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Remove posts with less than X words\n",
    "#min_words = 15\n",
    "#print(\"Before : Number of posts\", len(data)) \n",
    "data[\"no. of. words\"] = data[\"lyrics\"].apply(lambda x: len(re.findall(r'\\w+', x)))\n",
    "#data = data[data[\"no. of. words\"] >= min_words]\n",
    "data.sample(7)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Pre-Processing Stage\n",
    "preprocess the lyric by using Lemmitization technique. \n",
    "- Lemmatization is the process of grouping together the different inflected forms of a word so they can be analysed as a single item. \n",
    "- Lemmatization is similar to stemming but it brings context to the words, hence we use this instead in our model. So it links words with similar meaning to one word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatiser = WordNetLemmatizer()\n",
    "\n",
    "# Remove the stop words for speed \n",
    "useless_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarizing the each personality type feature\n",
    "# Splitting the MBTI personality into 4 letters and binarizing it\n",
    "\n",
    "b_Pers = {'I':0, 'E':1, 'N':0, 'S':1, 'F':0, 'T':1, 'J':0, 'P':1}\n",
    "b_Pers_list = [{0:'I', 1:'E'}, {0:'N', 1:'S'}, {0:'F', 1:'T'}, {0:'J', 1:'P'}]\n",
    "\n",
    "def translate_personality(personality):\n",
    "    # transform mbti to binary vector\n",
    "    return [b_Pers[l] for l in personality]\n",
    "\n",
    "#To show result output for personality prediction\n",
    "def translate_back(personality):\n",
    "    # transform binary vector to mbti personality\n",
    "    s = \"\"\n",
    "    for i, l in enumerate(personality):\n",
    "        s += b_Pers_list[i][l]\n",
    "    return s\n",
    "\n",
    "list_personality_bin = np.array([translate_personality(p) for p in data.MBTI])\n",
    "print(\"Binarize MBTI list: \\n%s\" % list_personality_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.lyrics[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning of data in the lyric\n",
    "def pre_process_text(data, remove_stop_words=True):\n",
    "    list_personality = []\n",
    "    list_lyrics = []\n",
    "    len_data = len(data)\n",
    "    i=0\n",
    "      \n",
    "    for row in data.iterrows():\n",
    "        #Remove and clean comments\n",
    "        lyrics = row[1].lyrics\n",
    "\n",
    "        #Remove Non-words - keep only words\n",
    "        temp = re.sub(\"[^a-zA-Z]\", \" \", lyrics)\n",
    "\n",
    "        # Remove spaces > 1\n",
    "        temp = re.sub(' +', ' ', temp).lower()\n",
    "\n",
    "        #Remove multiple letter repeating words\n",
    "        temp = re.sub(r'([a-z])\\1{2,}[\\s|\\w]*', '', temp)\n",
    "\n",
    "        #Remove stop words\n",
    "        if remove_stop_words:\n",
    "            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ') if w not in useless_words])\n",
    "        else:\n",
    "            temp = \" \".join([lemmatiser.lemmatize(w) for w in temp.split(' ')])\n",
    "\n",
    "\n",
    "      # transform mbti to binary vector\n",
    "        type_labelized = translate_personality(row[1].MBTI) #or use lab_encoder.transform([row[1].type])[0]\n",
    "        list_personality.append(type_labelized)\n",
    "        # the cleaned data temp is passed here\n",
    "        list_lyrics.append(temp)\n",
    "\n",
    "  # returns the result\n",
    "    list_lyrics = np.array(list_lyrics)\n",
    "    list_personality = np.array(list_personality)\n",
    "    return list_lyrics, list_personality\n",
    "\n",
    "list_lyrics, list_personality  = pre_process_text(data, remove_stop_words=True)\n",
    "\n",
    "print(\"Example :\")\n",
    "print(\"\\nLyrics before preprocessing:\\n\\n\", data.lyrics[0])\n",
    "print(\"\\nLyrics after preprocessing:\\n\\n\", list_lyrics[0])\n",
    "print(\"\\nMBTI before preprocessing:\\n\\n\", data.MBTI[0])\n",
    "print(\"\\nMBTI after preprocessing:\\n\\n\", list_personality[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nRow, nCol = list_personality.shape\n",
    "print(f'No. of posts = {nRow}  and No. of Personalities = {nCol} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "# Tf–idf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tf–idf for feature engineering evaluates how relevant/important a word is to a document in a collection of documnets or corpus. As we train individual classifiers here, it is very useful for scoring words in machine learning algorithms for Natural Language Processing.\n",
    "\n",
    "For the model ,i vectorize using count vectorizer and tf-idf vectorizer keeping the words appearing 10% to 70% of the lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizing the database posts to a matrix of token counts for the model\n",
    "cntizer = CountVectorizer(analyzer=\"word\", \n",
    "                             max_features=770,  \n",
    "                             max_df=0.7,\n",
    "                             min_df=0.1) \n",
    "# the feature should be made of word n-gram \n",
    "# Learn the vocabulary dictionary and return term-document matrix\n",
    "print(\"Using CountVectorizer :\")\n",
    "X_cnt = cntizer.fit_transform(list_lyrics)\n",
    "\n",
    "#The enumerate object yields pairs containing a count and a value (useful for obtaining an indexed list)\n",
    "feature_names = list(enumerate(cntizer.get_feature_names()))\n",
    "print(\"10 feature names can be seen below\")\n",
    "print(feature_names[0:10])\n",
    "\n",
    "# For the Standardization or Feature Scaling Stage :-\n",
    "# Transform the count matrix to a normalized tf or tf-idf representation\n",
    "tfizer = TfidfTransformer()\n",
    "\n",
    "# Learn the idf vector (fit) and transform a count matrix to a tf-idf representation\n",
    "print(\"\\nUsing Tf-idf :\")\n",
    "\n",
    "print(\"Now the dataset size is as below\")\n",
    "X_tfidf =  tfizer.fit_transform(X_cnt).toarray()\n",
    "print(X_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting into X and Y variable\n",
    "split the features as :\n",
    "\n",
    "X: lyrics in TF-IDF representation\n",
    "\n",
    "Y: Personality type in Binarized MBTI form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality_type = [ \"IE: Introversion (I) / Extroversion (E)\", \"NS: Intuition (N) / Sensing (S)\", \n",
    "                   \"FT: Feeling (F) / Thinking (T)\", \"JP: Judging (J) / Perceiving (P)\"  ]\n",
    "\n",
    "for l in range(len(personality_type)):\n",
    "    print(personality_type[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"X: 1st lyrics in tf-idf representation\\n%s\" % X_tfidf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For MBTI personality type : %s\" % translate_back(list_personality[0,:]))\n",
    "print(\"Y : Binarized MBTI 1st row: %s\" % list_personality[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training & Evaluating Models\n",
    "# lyrics in tf-idf representation\n",
    "X = X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "\n",
    "param['n_estimators'] = 200 #100\n",
    "param['max_depth'] = 2 #3\n",
    "param['nthread'] = 8 #1\n",
    "param['learning_rate'] = 0.2 #0.1\n",
    "\n",
    "# Individually training each mbti personlity type\n",
    "for l in range(len(personality_type)):\n",
    "    Y = list_personality[:,l]\n",
    "\n",
    "    # split data into train and test sets\n",
    "    seed = 7\n",
    "    test_size = 0.33\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "    # fit model on training data\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    # make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    \n",
    "    \n",
    "    #EVALUATION METRICS\n",
    "    import sklearn.metrics as metrics\n",
    "        \n",
    "    # calculate MAE\n",
    "    error = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    #MSE  \n",
    "    import math\n",
    "    MSE = mean_squared_error(y_test, predictions)\n",
    "    RMSE = math.sqrt(MSE)\n",
    "    #r squared    \n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    # display\n",
    "    # Model Recall: what percentage of positive tuples are labelled as such?\n",
    "    print(\"Recall:\",metrics.classification_report(y_test, predictions))\n",
    "    print(\"%s Accuracy: %.2f%%\" % (personality_type[l], accuracy * 100.0))\n",
    "    print(\"%s Mean absolute error : %.2f%%\" % (personality_type[l], error))\n",
    "    print(\"%s Root Mean Square Error: %.2f%%\" % (personality_type[l], RMSE))\n",
    "    print(\"%s r-squared : %.2f%%\" % (personality_type[l], r2 ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#prediction with unclean lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#web scraping part -lyrics \n",
    "\n",
    "# Log into Genius API with the Authorization Code\n",
    "client_access_token='yIyA-7gLpCLUtkU7Udq05X452sNQTNddQdcsRaPeVkz2M_xRuYXwW0pjC7sYu3Nq'\n",
    "LyricsGenius = lyricsgenius.Genius(client_access_token)\n",
    "\n",
    "# The package got some timeout issue so these two lines are needed. If you don't then there will be error when you scrape\n",
    "# Source: https://github.com/johnwmillr/LyricsGenius/issues/121\n",
    "LyricsGenius.timeout = 15  #timeout\n",
    "LyricsGenius.sleep = 5\n",
    "\n",
    "# Create an array to store each song's lyric\n",
    "lyrics_input = []\n",
    "\n",
    "inputt = ['shy martin - are you happy', 'summer walker - body'] # NEED TO EDIT THIS PART FOR STREAMLIT\n",
    "# Traverse through the database, get the song's lyrics from title, and do some preprocessing\n",
    "for i in inputt:\n",
    "    # get title\n",
    "    #song_title = ['sza - love galore', 'sza - good days']\n",
    "    \n",
    "    # search for song in genius.com\n",
    "    searched_song = LyricsGenius.search_song(i)\n",
    "    \n",
    "    # if we can't find a song's lyrics then skip and append empty string\n",
    "    if searched_song is None:\n",
    "        lyrics_arr.append(\"\")\n",
    "        continue\n",
    "        \n",
    "    # get the lyric\n",
    "    lyric = searched_song.lyrics\n",
    "    \n",
    "    # replace the lyrics newline with \". \"\n",
    "    lyric = lyric.replace(\"\\n\", \". \")\n",
    "    \n",
    "    # remove initial non-lyrics character:\n",
    "    # Source: https://thispointer.com/remove-string-before-a-specific-character-in-python/\n",
    "    # lyric = lyric[lyric.index('.') + 1 :]\n",
    "    \n",
    "    # append the processed lyric to the array\n",
    "    lyrics_input.append(lyric)\n",
    "    \n",
    "    # remove initial non-lyrics character:\n",
    "    #remove_words = '|'.join(['Chorus', 'Lyrics', 'Intro', 'Verse','Outro','Post-Chorus:','Pre-Chorus', 'Embed','Bridge'])\n",
    "    #lyrics_arr = lyrics_arr.str.replace(remove_words, '')\n",
    "    \n",
    "lyrics_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#li = ' '.join([str(x) for x in lyrics_input]) - for streamlit\n",
    "li = \n",
    "\n",
    "md = pd.DataFrame(data={'MBTI': [''], 'lyrics': [li]})\n",
    "li, dummy  = pre_process_text(md, remove_stop_words=True)\n",
    "my_X_cnt = cntizer.transform(li)\n",
    "my_X_tfidf =  tfizer.transform(my_X_cnt).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "param['n_estimators'] = 200\n",
    "param['max_depth'] = 2\n",
    "param['nthread'] = 8\n",
    "param['learning_rate'] = 0.2\n",
    "\n",
    "#XGBoost model for MBTI dataset\n",
    "result = []\n",
    "# Individually training each mbti personlity type\n",
    "for l in range(len(personality_type)):\n",
    "    print(\"%s classifier trained\" % (personality_type[l]))\n",
    "    \n",
    "    Y = list_personality[:,l]\n",
    "\n",
    "    # split data into train and test sets\n",
    "    seed = 7\n",
    "    test_size = 0.33\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=7)\n",
    "\n",
    "    # fit model on training data\n",
    "    model = XGBClassifier(**param)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # make predictions for my  data\n",
    "    y_pred = model.predict(my_X_tfidf)\n",
    "    result.append(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The result is: \", translate_back(result)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
